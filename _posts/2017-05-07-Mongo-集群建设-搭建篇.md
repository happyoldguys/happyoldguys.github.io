---
layout: post
title: MongoDB-集群建设-搭建篇
date: 2017-05-07 17:00:00
tags: 技术
---
&emsp;&emsp;上一篇文章我们讲述了MongoDB的集群，今天我们来完整的整个操作进行演示，此次演示使用的Mongo版本是3.2，系统选择Centos6.8 x64（阿里云主机3台），好了废话不多说下面我们就开始来搭建。（关于Mongod在启动时需要的lib库只要安装snmpd就可以了，如果是办公网环境只要source下环境变量就可以了）

###架构图：

<img src="https://happyoldguys.github.io/assets/img/Mongo Sharding - 办公环境.jpeg" style="display:block;margin:auto"/>

###一、准备数据节点（shard）

1.创建数据目录：

>主机：10.6.0.4

>mkdir mongo-keyfile

>mkdir mongo-shard1-master_31000

>mkdir mongo-shard2-slave_32001

>主机：10.6.0.5

>mkdir mongo-keyfile

>mkdir mongo-shard2-master_31001

>mkdir mongo-shard1-slave_32000

2.创建基础配置文件：

mongo.cnf
>此处需在10.6.0.4与10.6.0.5各目录下都创建，注意修改相关参数

>storageEngine = wiredTiger

>wiredTigerCacheSizeGB = 2

>syncdelay = 30

>wiredTigerCollectionBlockCompressor = snappy

>directoryperdb=true

>oplogSize=1024

>logappend=true

>fork=true

>nounixsocket=true

>nohttpinterface=true

>journal = true

>port=31000

>dbpath=/mongo-shard1-master_31000/db

>bind_ip=10.6.0.4,127.0.0.1

>logpath=/mongo-shard1-master_31000/mongodb.log

>pidfilepath=/mongo-shard1-master_31000/mongodb.pid

>shardsvr=true

3.创建认证用户：
>此处需在10.6.0.4与10.6.0.5的Master主机上启动进程并添加用户，Slave不用添加是因为后期会同步Master的数据

>./mongod -f /mongo-shard1-master_31000/mongo.cnf

>./mongo --port 31000

>\>use admin

>\>db.createUser({user:"UserAdmin",pwd:"password",roles:[{role:"userAdminAnyDatabase",db:"admin"}]});

>\>db.createUser({user:"RootAdmin",pwd:"password",roles:[{role:"root",db:"admin"}]});

4.创建共享密钥：
>只需在一台主机上创建密钥，共所有mongo主机做认证使用

>openssl rand -base64 741 > mongodb-keyfile

>chmod 600 mongodb-keyfile

>chown mongod.mongod mongodb-keyfile

5.在配置文件中添加ReplSet信息
>杀掉先前的mongo进程后在各配置文件中添加如下信息，注意修改相关参数

>replSet=replser_1/10.6.0.4:31000,10.6.0.5:32000,

>auth=true

>keyFile=/mongo-keyfile/mongodb-keyfile

6.启动并登入mongo进行初始化环境
>登入10.6.0.4与10.6.0.5的Master添加各角色，注意修改相关参数

>./mongod --quiet -f /mongo-shard1-master_31000/mongo.cnf --replSet replser_1 --shardsvr --auth

>./mongo --port 31000 -uRootAdmin -ppassword --authenticationDatabase admin

>\>rs.initiate();

>\>rs.add({host:"10.6.0.5:32000",priority:0});

>添加完相关角色后启动各角色进程检查同步状态，是否在同一个副本集中，并且在Master上创建条目在Slave上查看，测试主从同步无误后，至此shard节点就算配置完毕了

###二、搭建配置服务器（configsvr）

1.创建数据目录

>主机：10.6.0.6

>mkdir mongo-keyfile

>mkdir mongo-confisvr_31000

>mkdir mongo-confisvr_32000

>mkdir mongo-confisvr_33000

2.创建基础配置文件：

mongo.cnf
>需在各数据目录下都创建，注意修改相关参数

>storageEngine = wiredTiger

>wiredTigerCacheSizeGB = 2

>syncdelay = 30

>wiredTigerCollectionBlockCompressor = snappy

>directoryperdb=true

>oplogSize=1024

>logappend=true

>fork=true

>nounixsocket=true

>nohttpinterface=true

>journal = true

>port=31000

>dbpath=/mongo-confisvr_31000/db

>bind_ip=10.6.0.6,127.0.0.1

>logpath=/mongo-confisvr_31000/mongodb.log

>pidfilepath=/mongo-confisvr_31000/mongodb.pid

>configsvr=true

3.创建认证用户：
>此处需在10.6.0.6的Configsvr Master主机上启动进程并添加用户，Configsvr Slave不用添加是因为后期会同步Configsvr Master的数据

>./mongod -f /mongo-confisvr_31000/mongo.cnf

>./mongo --port 31000

>\>use admin

>\>db.createUser({user:"UserAdmin",pwd:"password",roles:[{role:"userAdminAnyDatabase",db:"admin"}]});

>\>db.createUser({user:"RootAdmin",pwd:"password",roles:[{role:"root",db:"admin"}]});

4.添加replSet、认证、密钥：
>将先前做shard时的密钥传过来，修改配置文件

>杀掉先前的mongo进程后在各配置文件中添加如下信息，注意修改相关参数

>replSet=configserver/10.6.0.6:31000,10.6.0.6:32000,10.6.0.6:33000,

>auth=true

>keyFile=/mongo-keyfile/mongodb-keyfile

5.启动并登入mongo进行初始化环境
>登入10.6.0.6的Configsvr Master添加各角色，注意修改相关参数

>./mongod --quiet -f /mongo-confisvr_31000/mongo.cnf --replSet configserver --configsvr --auth

>./mongo --port 31000 -uRootAdmin -ppassword --authenticationDatabase admin

>\>rs.initiate();

>\>rs.add({host:"10.6.0.6:32000",priority:0});

>\>rs.add({host:"10.6.0.6:33000",priority:0});

>添加完相关角色后启动各角色进程检查角色状态是否同步，是否同在一个副本集中

6.添加抢占优先权
>因目前configsvr无法添加Arbiter角色，故只有将从的priority权调高，防止在主挂掉后无人抢占，在主角色下执行如下命令

>\> cfg = rs.config();

>\>cfg.members[0].priority = 10;

>\>cfg.members[1].priority = 9;

>\>cfg.members[2].priority = 8;

>\>rs.reconfig(cfg);

>修改完毕后执行rs.config()查看状态

###三、搭建路由服务器（Mongos）

1.创建数据目录

>主机：10.6.0.6

>mkdir mongo-keyfile

>mkdir mongo-mongos_38000

>mkdir mongo-mongos_39000

2.启动mongos程序并执行shard划分
>这里启动mongos时configdb只要指向主的那台就可以，只要configsvr设置了抢占优先级，无论configsvr如何切换主，这边都是可以读到相关信息

>\>./mongos --port 38000 --configdb configserver/10.6.0.6:31000 --logpath /mongo-mongos_38000/38000.log --keyFile /mongo-keyfile/mongodb-keyfile --fork

>\>./mongos --port 39000 --configdb configserver/10.6.0.6:31000 --logpath /mongo-mongos_39000/39000.log --keyFile /mongo-keyfile/mongodb-keyfile --fork

>登入mongos并在其中一台mongos执行相关命令即可

>./mongo 10.6.0.6:38000

>\>sh.addShard("shard1/10.6.0.6:38000")

>\>sh.addShard("shard2/10.6.0.6:39000")

>查看状态 \>sh.status() 确认shard已创建

>停止balancer（均衡器）

>\>sh.setBalancerState(false)

>指定各个Database分布，关闭随机分片功能

>在做这步前要在各个主shard上创建好相应的库

>\>sh.enableSharding("库名")

>\>use config
	
>\>db.databases.find()
	
>\>db.databases.update({"_id":"库名"},{$set:{"primary":"shard1","partitioned":false}})

>\>db.databases.find()

>查看状态 \>sh.status() 确认shard已划分完毕并关闭了随机分片

>以上操作确认无误后需刷新以上所执行的命令

>\>use admin

>\>db.runCommand("flushRouterConfig")

&emsp;&emsp;以上就是MongoDB的指定分片方法，根据部署环境可能会有微小的不同之处，最重要的还是每步做完后需检查确认所做操作无误，以免盲目进行到最后不知道哪里产生了问题。